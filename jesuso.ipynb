# Importar las librerías necesarias
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler, StringIndexer
from pyspark.ml.classification import DecisionTreeClassifier, GBTClassifier, RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

# Crear una SparkSession
spark = SparkSession.builder \
    .appName("Iris MLlib Example") \
    .getOrCreate()

# Cargar los datos
data = spark.read.format("csv") \
    .option("inferSchema", "true") \
    .option("header", "true") \
    .load("iris.csv")  # Asegúrate de que el path al archivo sea correcto

# Mostrar el esquema para verificar que los datos se hayan cargado correctamente
data.printSchema()

# Usar VectorAssembler para transformar las columnas de características en un único vector de características
assembler = VectorAssembler(
    inputCols=["sepal_length", "sepal_width", "petal_length", "petal_width"],
    outputCol="features")
data_transformed = assembler.transform(data)

# Convertir la columna de etiquetas 'species' en etiquetas numéricas
indexer = StringIndexer(inputCol="species", outputCol="label")
data_final = indexer.fit(data_transformed).transform(data_transformed)

# Dividir los datos en conjuntos de entrenamiento y prueba
train_data, test_data = data_final.randomSplit([0.7, 0.3], seed=42)

# Definir y ajustar el modelo de Decision Tree
dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')
dt_model = dt.fit(train_data)
dt_predictions = dt_model.transform(test_data)

# Definir y ajustar el modelo de Gradient-boosted Tree
gbt = GBTClassifier(featuresCol='features', labelCol='label')
gbt_model = gbt.fit(train_data)
gbt_predictions = gbt_model.transform(test_data)

# Definir y ajustar el modelo de Random Forest
rf = RandomForestClassifier(featuresCol='features', labelCol='label')
rf_model = rf.fit(train_data)
rf_predictions = rf_model.transform(test_data)

# Evaluador para medir la precisión de los modelos
evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")

# Calcular la precisión de cada modelo
dt_accuracy = evaluator.evaluate(dt_predictions)
gbt_accuracy = evaluator.evaluate(gbt_predictions)
rf_accuracy = evaluator.evaluate(rf_predictions)

# Imprimir las precisiones
print("Accuracy of Decision Tree: ", dt_accuracy)
print("Accuracy of Gradient-boosted Tree: ", gbt_accuracy)
print("Accuracy of Random Forest: ", rf_accuracy)

# Detener la SparkSession
spark.stop()
